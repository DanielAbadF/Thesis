{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.datasets as datasets\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81928629c1e04f52ac90a62f74d9d172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/59926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14699537e9934c8e82e5ffefd8d55cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"C:/Thesis/Dataset4classes\", num_proc=3)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "ROOT_DIR = os.path.join(cwd, \"C:/Thesis/Dataset4classes/train\")\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for folder in os.listdir(ROOT_DIR):\n",
    "    for file in os.listdir(os.path.join(ROOT_DIR, folder)):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            full_name = os.path.join(ROOT_DIR, folder, file)\n",
    "            labels[full_name] = folder\n",
    "\n",
    "files = labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\abadd/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "dinov2_vits14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vitl14\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "dinov2_vits14.to(device)\n",
    "transform_image = T.Compose([\n",
    "    T.Resize(244),                # Escala el lado más corto a 244 píxeles\n",
    "    T.CenterCrop(224),            # Recorta una región central de 224x224\n",
    "    T.ToTensor(),                 # Convierte la imagen a tensor\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normaliza con mean y std de ImageNet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor de entrada y muévelo al dispositivo\n",
    "dummy_input = torch.rand(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Genera los embeddings\n",
    "embeddings = dinov2_vits14(dummy_input)\n",
    "\n",
    "# Verifica las dimensiones de los embeddings\n",
    "print(embeddings.shape)                 # Verificar dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load an image and return a tensor that can be used as an input to DINOv2.\n",
    "    \"\"\"\n",
    "    img = Image.open(img)\n",
    "\n",
    "    transformed_img = transform_image(img)[:3].unsqueeze(0)\n",
    "\n",
    "    return transformed_img\n",
    "\n",
    "def compute_embeddings(files: list) -> dict:\n",
    "    \"\"\"\n",
    "    Create an index that contains all of the images in the specified list of files.\n",
    "    \"\"\"\n",
    "    all_embeddings = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for i, file in enumerate(tqdm(files)):\n",
    "        embeddings = dinov2_vits14(load_image(file).to(device))\n",
    "\n",
    "        all_embeddings[file] = np.array(embeddings[0].cpu().numpy()).reshape(1, -1).tolist()\n",
    "\n",
    "    with open(\"all_embeddings.json\", \"w\") as f:\n",
    "        f.write(json.dumps(all_embeddings))\n",
    "\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead560d618074863a45cd5142ea15b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38591 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = compute_embeddings(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from random import shuffle\n",
    "\n",
    "y = [labels[file] for file in files]\n",
    "\n",
    "embedding_list = list(embeddings.values())\n",
    "\n",
    "combined = list(zip(embedding_list, y))\n",
    "\n",
    "# Barajar\n",
    "shuffle(combined)\n",
    "\n",
    "# Separar nuevamente\n",
    "embedding_list, y = zip(*combined)\n",
    "embedding_list = np.array(embedding_list).squeeze(1)  # Quita la dimensión de tamaño 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Supongamos que ya tienes tus embeddings y etiquetas en arrays\n",
    "# embedding_array: numpy array con tus datos de entrada\n",
    "# y_array: numpy array con tus etiquetas\n",
    "\n",
    "# Definir el modelo SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Definir el espacio de búsqueda para los hiperparámetros\n",
    "param_grid = {\n",
    "    'C': [10],             # Regularización\n",
    "    'gamma': [ 0.001],    # Parámetro del kernel RBF\n",
    "    'kernel': ['rbf']                  # Usaremos kernel RBF en este ejemplo\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',                # Métrica de evaluación (puedes cambiarla según el problema)\n",
    "    cv=5,                              # Validación cruzada (5 pliegues en este caso)\n",
    "    verbose=2,\n",
    "    n_jobs=-1                          # Usar todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros\n",
    "grid_search.fit(embedding_list, y)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y la puntuación asociada\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluar en datos de entrenamiento (opcional)\n",
    "y_pred = grid_search.best_estimator_.predict(embedding_list)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join(cwd, \"C:/Thesis/Dataset4classes/valid\")\n",
    "\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for folder in os.listdir(ROOT_DIR):\n",
    "    for file in os.listdir(os.path.join(ROOT_DIR, folder)):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            full_name = os.path.join(ROOT_DIR, folder, file)\n",
    "            labels[full_name] = folder\n",
    "\n",
    "testfiles = labels.keys()\n",
    "testembeddings = compute_embeddings(testfiles)\n",
    "\n",
    "y_val = [labels[file] for file in testfiles]\n",
    "y_val_pred = grid_search.best_estimator_.predict(np.array(list(testembeddings.values())).reshape(-1, 384))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular matriz de confusión\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "labels_names = ds['train'].features['label'].names  # Nombres de las clases\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "model = XGBClassifier(n_estimators=495, \n",
    "                      max_depth=9, \n",
    "                      learning_rate= 0.07513291174284646, \n",
    "                      subsample=0.8103606987549683, \n",
    "                      colsample_bytree = 0.7897168158886071, \n",
    "                      gamma = 0.2932845334464851, \n",
    "                      reg_alpha = 8.968869453424377,\n",
    "                      reg_lambda = 6.468487200733069, \n",
    "                      min_child_weight = 8)\n",
    "\n",
    "model.fit(embedding_list, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_encoded = label_encoder.fit_transform(y_val)\n",
    "y_pred = model.predict(np.array(list(testembeddings.values())).squeeze(1))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val_encoded, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [300],  # Número de árboles en el bosque\n",
    "    'max_depth': [7, 11],               # Profundidad máxima del árbol\n",
    "    'learning_rate': [0.15],    # Tasa de aprendizaje\n",
    "    'subsample': [0.9],           # Proporción de muestras utilizadas para entrenar cada árbol\n",
    "    'colsample_bytree': [0.7, 0.9],    # Proporción de características utilizadas para entrenar cada árbol\n",
    "    'gamma': [0.4],            # Reducción mínima de la pérdida requerida para hacer una división\n",
    "    'reg_alpha': [0.5, 1.0],                  # Término de regularización L1 en pesos\n",
    "    'reg_lambda': [1.0],                 # Término de regularización L2 en pesos\n",
    "    'min_child_weight': [1]               # Peso mínimo necesario para crear un nuevo nodo en el árbol\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor'),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=4,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros\n",
    "grid_search_xgb.fit(embedding_list, y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejores hiperparámetros:\", grid_search_xgb.best_params_)\n",
    "print(\"Mejor puntuación:\", grid_search_xgb.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_xgb = grid_search_xgb.best_estimator_.predict(np.array(list(testembeddings.values())).squeeze(1))\n",
    "\n",
    "print(\"Accuracy en datos de validación:\", accuracy_score(y_val_encoded, y_val_pred_xgb))\n",
    "print(\"Classification Report en datos de validación:\\n\", classification_report(y_val_encoded, y_val_pred_xgb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
